{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BQDataset():\n",
    "    def __init__(self, path):\n",
    "        self.dataset = open(path,encoding=\"utf-8\")\n",
    "\n",
    "        self.dataset = [json.loads(instance) for instance in self.dataset ]\n",
    "\n",
    "\n",
    "        self.passages = []\n",
    "        self.questions = []\n",
    "        self.answers = []\n",
    "        self.titles = []\n",
    "\n",
    "        for inst in self.dataset:\n",
    "            self.passages.append(inst[\"passage\"])\n",
    "            self.questions.append(inst[\"question\"])\n",
    "            self.answers.append(inst[\"answer\"])\n",
    "            self.titles.append(inst[\"title\"])\n",
    "\n",
    "    def get_dataset(self):\n",
    "        return self.dataset\n",
    "\n",
    "    def get_split(self):\n",
    "\n",
    "        return self.passages,self.questions, self.answers\n",
    "\n",
    "\n",
    "bqd = BQDataset(\"datasets/train.jsonl\")\n",
    "dataset = bqd.get_dataset()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "9427"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "class BaselineModel:\n",
    "\n",
    "\n",
    "    def __init__(self, w2v_model,embedding_size, P,Q,A,seed = 0):\n",
    "\n",
    "        self.w2v = w2v_model\n",
    "        self.embedding_size = embedding_size\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.A = A\n",
    "\n",
    "        self.X, self.y = self.get_X_y(self.P,self.Q,self.A,embedding_size,self.w2v)\n",
    "\n",
    "        self.X_train, self.X_dev, self.y_train, self.y_dev = sk.model_selection.train_test_split(self.X,self.y,random_state=seed,shuffle=True,train_size=0.7)\n",
    "\n",
    "    def get_X_y(self,P,Q,A, embedding_size, w2v):\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(len(P)):\n",
    "\n",
    "            p_ = P[i]\n",
    "            q_ = Q[i]\n",
    "\n",
    "            p_vect = np.zeros(embedding_size)\n",
    "            q_vect = np.zeros(embedding_size)\n",
    "\n",
    "            for word in p_:\n",
    "                if word in w2v.wv.key_to_index:\n",
    "\n",
    "                    p_vect += w2v.wv.get_vector(word)\n",
    "\n",
    "            for word in q_:\n",
    "                if word in w2v.wv.key_to_index:\n",
    "                    q_vect += w2v.wv.get_vector(word)\n",
    "\n",
    "\n",
    "            p_vect /= len(p_)\n",
    "            q_vect /= len(q_)\n",
    "\n",
    "            X.append(np.concatenate([p_vect,q_vect]))\n",
    "            y.append(0 if A[i] == False else 1)\n",
    "\n",
    "        return X,y\n",
    "\n",
    "\n",
    "    def evaluate(self, classifier):\n",
    "\n",
    "        classifier.fit(self.X_train,self.y_train)\n",
    "\n",
    "\n",
    "\n",
    "        train_score = f1_score(self.y_train,classifier.predict(self.X_train))\n",
    "        dev_score = f1_score(self.y_dev,classifier.predict(self.X_dev))\n",
    "\n",
    "\n",
    "        print(f\"f1-score for train set: {train_score}\")\n",
    "        print(f\"f1-score for dev set: {dev_score}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "(7601333, 9613800)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "embedding_size = 100\n",
    "\n",
    "passages, questions, answers = bqd.get_split()\n",
    "\n",
    "sentences = list(passages)\n",
    "sentences.extend(questions)\n",
    "\n",
    "\n",
    "p_ = []\n",
    "for p in passages:\n",
    "    p_.append(p.split(\" \"))\n",
    "\n",
    "q_ = []\n",
    "for q in questions:\n",
    "    q_.append(q.split(\" \"))\n",
    "\n",
    "\n",
    "\n",
    "s_ = []\n",
    "for i in range(len(p_)):\n",
    "    s = list(p_[i])\n",
    "    s.extend(q_[i])\n",
    "    s_.append(s)\n",
    "\n",
    "sentences = s_\n",
    "\n",
    "w2v_model = Word2Vec(sentences=sentences,vector_size=embedding_size, window= 5, min_count= 1, workers= 4)\n",
    "classifier = LogisticRegression(penalty=\"l2\",max_iter=10000)\n",
    "\n",
    "w2v_model.train(sentences,total_examples=len(sentences),epochs=10)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score for train set: 0.7709947977492304\n",
      "f1-score for dev set: 0.7500625469101827\n"
     ]
    }
   ],
   "source": [
    "k = BaselineModel(w2v_model,embedding_size,p_,q_,answers)\n",
    "k.evaluate(classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-3.10293568e-01,  3.04078892e-01,  7.99123367e-01, -5.96259765e-01,\n       -6.04488989e-02, -5.27231544e-01,  5.47070851e-01,  1.01012521e-01,\n       -4.57029295e-02,  3.23070695e-01,  5.59191915e-02, -2.08565610e-01,\n       -4.24085065e-01,  3.67575266e-02, -5.26636049e-01, -2.36994107e-01,\n        1.89451844e-01,  1.01375778e-01, -5.83698628e-02, -8.13871985e-01,\n        2.32357427e-01,  1.17835589e-02, -3.27943195e-01, -2.88370005e-01,\n       -5.62386448e-01, -2.93313111e-02,  6.44427421e-02,  3.29379867e-01,\n       -8.37064570e-01, -1.79148597e-01,  6.24268914e-01, -5.51920648e-01,\n        2.92520956e-01,  7.84171486e-02, -2.21777943e-01,  8.71184795e-01,\n        4.31599037e-01,  9.97845171e-02, -1.03633612e+00, -5.68279108e-01,\n       -5.08828799e-01, -4.11109750e-01, -1.50489201e+00, -5.53760649e-01,\n        7.97723324e-01, -2.78819563e-01,  6.26712295e-02,  1.56732191e-03,\n        3.04071621e-01,  3.26310693e-01,  3.10146469e-02,  7.11179911e-02,\n       -1.47398058e-01,  2.38771881e-01, -9.98415348e-01,  6.29303494e-01,\n        1.63505874e-01, -6.41308787e-01, -1.23787849e+00, -8.41034321e-02,\n        3.42343295e-01,  5.44976996e-01, -2.91424775e-01, -9.74699313e-01,\n        3.12301997e-01,  4.49449371e-01, -2.56955782e-01,  5.20544815e-01,\n       -5.17462202e-01,  2.39265316e-01, -3.75783074e-01,  1.02998584e+00,\n        2.95668892e-01, -4.66197223e-01,  2.64780808e-01,  4.90816862e-01,\n       -2.95797946e-01,  2.14392871e-01, -1.32669392e+00,  1.75323785e-01,\n       -2.48705149e-01,  5.31173996e-02, -2.05737390e-01,  4.90833845e-01,\n        3.33532685e-01,  5.86515800e-02,  2.41443527e-01,  4.12623832e-01,\n       -1.84645878e-01,  4.49855530e-01,  1.63956126e-01, -1.27524743e-01,\n        2.43735387e-01, -2.29667421e-01,  9.00741824e-01,  9.01085558e-02,\n       -7.62298699e-01, -4.34409279e-01,  6.80472182e-01,  1.63490752e+00,\n        4.97894527e-01,  3.18615431e-01, -5.86564858e-01, -7.71126663e-01,\n        5.14991287e-01, -5.96350912e-01,  1.12150263e+00,  1.76545637e-02,\n       -7.25102391e-01, -4.16453172e-01,  6.43581018e-01, -1.89340057e-01,\n       -6.65938540e-01, -2.74316568e-01,  1.68135799e-01, -1.77029758e-02,\n        2.54978990e-01, -6.19121335e-01,  1.82514124e-01, -6.35571798e-01,\n        1.28824481e+00,  1.19482326e-01,  1.01941547e+00, -4.41800698e-01,\n       -1.87463318e-01,  3.75578283e-01,  2.84400121e-01,  1.04388895e-01,\n        7.75776574e-01, -6.96191395e-01,  7.56255175e-01, -1.82707853e-01,\n        2.92346152e-01, -1.20946470e+00, -4.02147833e-01,  4.94151467e-02,\n        2.25937605e-01, -4.57539736e-01, -8.23449382e-01, -1.53177083e+00,\n       -4.41814167e-01, -7.04495605e-01, -1.20188465e+00, -1.23289415e+00,\n        7.78320828e-01, -5.33798320e-01,  4.01963006e-01,  6.19472948e-01,\n       -6.04134318e-01,  2.13189048e-01,  6.17456645e-01, -2.11047834e-03,\n        2.39239703e-01, -7.80226842e-01, -5.20976196e-01, -1.66117095e+00,\n        4.81741877e-01, -3.56378987e-01, -1.11668271e+00,  7.50230650e-01,\n        6.97392649e-01, -2.52349516e-02, -6.35164676e-02, -9.71874142e-01,\n        2.33295106e-01,  5.64705094e-01, -3.09012371e-01,  3.30769567e-01,\n       -5.30677984e-01, -1.31357103e-01, -6.61169205e-02,  9.08516946e-01,\n        5.64285300e-01,  2.15367735e-01, -2.32322795e-01, -1.11791923e+00,\n       -9.14846835e-01,  1.23059072e+00, -7.08472830e-01, -7.40179233e-03,\n       -2.63556869e-01, -2.05028118e-01,  1.81563016e-01,  3.92258994e-01,\n        4.26954706e-01,  5.74097107e-02,  8.58136733e-01,  3.45199513e-02,\n       -1.50972183e-01, -3.82940379e-01,  8.83710489e-01, -9.59016474e-01,\n       -1.53964499e-01, -1.43544735e-01,  7.54147051e-01,  3.35982958e-01,\n       -1.65791137e-01, -7.34572673e-01, -2.06664429e-02,  6.61751239e-01])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.X_train[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
